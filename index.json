[{"authors":["admin"],"categories":null,"content":"Liangming Pan (潘亮铭) is a final-year Computer Science Ph.D. student at the National University of Singapore, jointly advised by Prof. Min-Yen Kan and Prof. Tat-Seng Chua. Before joining NUS, he received Master\u0026rsquo;s degree from the School of Computer Science at Tsinghua University in June 2017, working with Prof. Juanzi Li and Prof. Jie Tang. He obtained his Bachelor\u0026rsquo;s degree from Beihang University (2010 - 2014).\nHis broad research interests include knowledge bases, natural language processing, and data mining. To be specific, his research topics include neural question generation, text style transfer, and zero/few-shot image recognition.\nHe is now joining the UC Santa Barbara Natural Language Processing Group as a visiting Ph.D. student, supervised by Prof. William Wang.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://teacherpeterpan.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Liangming Pan (潘亮铭) is a final-year Computer Science Ph.D. student at the National University of Singapore, jointly advised by Prof. Min-Yen Kan and Prof. Tat-Seng Chua. Before joining NUS, he received Master\u0026rsquo;s degree from the School of Computer Science at Tsinghua University in June 2017, working with Prof. Juanzi Li and Prof. Jie Tang. He obtained his Bachelor\u0026rsquo;s degree from Beihang University (2010 - 2014).\nHis broad research interests include knowledge bases, natural language processing, and data mining.","tags":null,"title":"Liangming Pan","type":"authors"},{"authors":[],"categories":[],"content":"","date":1617058546,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617058546,"objectID":"e728be6bdab9997469e1b861f8d5b8a4","permalink":"https://teacherpeterpan.github.io/project/mqa-qg/","publishdate":"2021-03-29T15:55:46-07:00","relpermalink":"/project/mqa-qg/","section":"project","summary":"'Codes for NAACL 2021 Paper \"Unsupervised Multi-hop Question Answering by Question Generation\". '","tags":["Question Generation"],"title":"Unsupervised-Multi-hop-QA","type":"project"},{"authors":["Liangming Pan","Wenhu Chen","Wenhan Xiong","Min-Yen Kan","William Yang Wang"],"categories":[],"content":"","date":1615442141,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615442141,"objectID":"118a4e142baa2b5973c1d51317bd79dd","permalink":"https://teacherpeterpan.github.io/publication/naacl21/","publishdate":"2021-03-10T21:55:41-08:00","relpermalink":"/publication/naacl21/","section":"publication","summary":"Obtaining training data for multi-hop question answering (QA) is time-consuming and resource-intensive. We explore the possibility to train a well-performed multi-hop QA model without referencing any human-labeled multi-hop question-answer pairs, i.e., unsupervised multi-hop QA. We propose MQA-QG, an unsupervised framework that can generate human-like multi-hop training data from both homogeneous and heterogeneous data sources. MQA-QG generates questions by first selecting/generating relevant information from each data source and then integrating the multiple information to form a multi-hop question. Using only generated training data, we can train a competent multi-hop QA which achieves 61% and 83% of the supervised learning performance for the HybridQA and the HotpotQA dataset, respectively. We also show that pretraining the QA system with the generated data would greatly reduce the demand for human-annotated training data. ","tags":[],"title":"Unsupervised Multi-hop Question Answering by Question Generation","type":"publication"},{"authors":["Yuxi Xie","Liangming Pan","Dongzhe Wang","Min-Yen Kan","Yansong Feng"],"categories":[],"content":"","date":1604727369,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604727369,"objectID":"269cbf5647448091877e39604fff6426","permalink":"https://teacherpeterpan.github.io/publication/coling20/","publishdate":"2020-11-06T21:36:09-08:00","relpermalink":"/publication/coling20/","section":"publication","summary":"Recent question generation (QG) approaches often utilize the sequence-to-sequence framework (Seq2Seq) to optimize the log-likelihood of ground-truth questions using teacher forcing. However, this training objective is inconsistent with actual question quality, which is often reflected by certain global properties such as whether the question can be answered by the document. As such, we directly optimize for QG-specific objectives via reinforcement learning to improve question quality. We design three different rewards that target to improve the fluency, relevance, and answerability of generated questions. We conduct both automatic and human evaluations in addition to a thorough analysis to explore the effect of each QG-specific reward. We find that optimizing question-specific rewards generally leads to better performance in automatic evaluation metrics. However, only the rewards that correlate well with human judgement (e.g., relevance) lead to real improvement in question quality. Optimizing for the others, especially answerability, introduces incorrect bias to the model, resulting in poor question quality.","tags":[],"title":"Exploring Question-Specific Rewards for Generating Deep Questions","type":"publication"},{"authors":["Zhiyuan Liu","Yixin Cao","Liangming Pan","Juanzi Li","Zhiyuan Liu","Tat-Seng Chua"],"categories":[],"content":"","date":1602566692,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602566692,"objectID":"63d78a51cf541d043d288d7dd8f8ce45","permalink":"https://teacherpeterpan.github.io/publication/emnlp20/","publishdate":"2020-10-12T22:24:52-07:00","relpermalink":"/publication/emnlp20/","section":"publication","summary":"Entity alignment (EA) aims at building a unified Knowledge Graph (KG) of rich content by linking the equivalent entities from various KGs. GNN-based EA methods present promising performances by modeling the KG structure defined by relation triples. However, attribute triples can also provide crucial alignment signal but have not been well explored yet. In this paper, we propose to utilize an attributed value encoder and partition the KG into subgraphs to model the various types of attribute triples efficiently. Besides, the performances of current EA methods are overestimated because of the name-bias of existing EA datasets. To make an objective evaluation, we propose a hard experimental setting where we select equivalent entity pairs with very different names as the test set. Under both the regular and hard settings, our method achieves significant improvements (5.10% on average Hits@1 in DBP15k) over 12 baselines in cross-lingual and monolingual datasets. Ablation studies on different subgraphs and a case study about attribute types further demonstrate the effectiveness of our method. Source code and data can be found at this https URL.","tags":[],"title":"Exploring and Evaluating Attributes, Values, and Structures for Entity Alignment","type":"publication"},{"authors":["Liangming Pan","Jingjing Chen","Jianlong Wu","Shaoteng Liu","Chong-Wah Ngo","Min-Yen Kan","Yu-Gang Jiang","Tat-Seng Chua"],"categories":[],"content":"","date":1597551852,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597551852,"objectID":"6e7bc11a87ac468c7ba73c3f76c64923","permalink":"https://teacherpeterpan.github.io/publication/acmmm-2020/","publishdate":"2020-08-15T21:24:12-07:00","relpermalink":"/publication/acmmm-2020/","section":"publication","summary":"Understanding food recipe requires anticipating the implicit causal effects of cooking actions, such that the recipe can be converted into a graph describing the temporal workflow of the recipe. This is a non-trivial task that involves common-sense reasoning. However, existing efforts rely on hand-crafted features to extract the workflow graph from recipes due to the lack of large-scale labeled datasets. Moreover, they fail to utilize the cooking images, which constitute an important part of food recipes. In this paper, we build MM-ReS, the first large-scale dataset for cooking workflow construction, consisting of 9,850 recipes with human-labeled workflow graphs. Cooking steps are multi-modal, featuring both text instructions and cooking images. We then propose a neural encoder-decoder model that utilizes both visual and textual information to construct the cooking workflow, which achieved over 20% performance gain over existing hand-crafted baselines. ","tags":[],"title":"Multi-modal Cooking Workflow Construction for Food Recipes","type":"publication"},{"authors":[],"categories":[],"content":"","date":1588208161,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588208161,"objectID":"402255db29d355cdf1c944fee248d3b8","permalink":"https://teacherpeterpan.github.io/project/sg-dqg/","publishdate":"2020-04-30T08:56:01+08:00","relpermalink":"/project/sg-dqg/","section":"project","summary":"This repository contains code and models for the paper: Semantic Graphs for Generating Deep Questions (ACL 2020). ","tags":["Question Generation"],"title":"SG-Deep Question Generation","type":"project"},{"authors":["Liangming Pan","Yuxi Xie","Yansong Feng","Tat-Seng Chua","Min-Yen Kan"],"categories":[],"content":"","date":1588046727,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588046727,"objectID":"f8f68b2e45098059e8d058a6547385f0","permalink":"https://teacherpeterpan.github.io/publication/acl20-qg/","publishdate":"2020-04-28T12:05:27+08:00","relpermalink":"/publication/acl20-qg/","section":"publication","summary":"This paper proposes the problem of Deep Question Generation (DQG), which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage. In order to capture the global structure of the document and facilitate reasoning, we propose a novel framework which first constructs a semantic-level graph for the input document and then encodes the semantic graph by introducing an attention-based GGNN (Att-GGNN). Afterwards, we fuse the document-level and graph-level representations to perform joint training of content selection and question decoding. On the HotpotQA deep-question centric dataset, our model greatly improves performance over questions requiring reasoning over multiple facts, leading to state-of-the-art performance. The code is publicly available at https://github.com/WING-NUS/SG-Deep-Question-Generation.","tags":[],"title":"Semantic Graphs for Generating Deep Questions","type":"publication"},{"authors":["Yixin Cao","Ruihao Shui","Liangming Pan","Min-Yen Kan","Zhiyuan Liu","Tat-Seng Chua"],"categories":[],"content":"","date":1587950204,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587950204,"objectID":"19091f232f7e9ea21f4ad11d26701470","permalink":"https://teacherpeterpan.github.io/publication/acl20-style/","publishdate":"2020-04-27T09:16:44+08:00","relpermalink":"/publication/acl20-style/","section":"publication","summary":"The curse of knowledge can impede communication between experts and laymen. We propose a new task of expertise style transfer and contribute a manually annotated dataset with the goal of alleviating such cognitive biases. Solving this task not only simplifies the professional language, but also improves the accuracy and expertise level of laymen descriptions using simple words. This is a challenging task, unaddressed in previous work, as it requires the models to have expert intelligence in order to modify text with a deep understanding of domain knowledge and structures. We establish the benchmark performance of five state-of-the-art models for style transfer and text simplification. The results demonstrate a significant gap between machine and human performance. We also discuss the challenges of automatic evaluation, to provide insights into future research directions. The dataset is publicly available at https://srhthu.github.io/expertise-style-transfer/.","tags":[],"title":"Expertise Style Transfer: A New Task Towards Better Communcation between Experts and Laymen","type":"publication"},{"authors":["Shaoteng Liu","Jingjing Chen","Liangming Pan","Chong-Wah Ngo","Tat-Seng Chua","Yu-Gang Jiang"],"categories":[],"content":"","date":1587777416,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587777416,"objectID":"7777de6db028b828f9af5e10f31772f9","permalink":"https://teacherpeterpan.github.io/publication/cvpr20/","publishdate":"2020-04-25T09:16:56+08:00","relpermalink":"/publication/cvpr20/","section":"publication","summary":"This paper proposes a Hyperbolic Visual Embedding Learning Network for zero-shot recognition. The network learns image embeddings in hyperbolic space, which is capable of preserving the hierarchical structure of semantic classes in low dimensions. Comparing with existing zero-shot learning approaches, the network is more robust because the embedding feature in hyperbolic space better represents class hierarchy and thereby avoid misleading resulted from unrelated siblings. Our network outperforms exiting baselines under hierarchical evaluation with an extremely challenging setting, i.e., learning only from 1,000 categories to recognize 20,841 unseen categories. While under flat evaluation, it has competitive performance as state-of-the-art methods but with five times lower embedding dimensions. Our code is publicly available.","tags":[],"title":"Hyperbolic Visual Embedding Learning for Zero-Shot Recognition","type":"publication"},{"authors":["Jingjing Chen","Liangming Pan","Zhipeng Wei","Xiang Wang","Chong-Wah Ngo","Tat-Seng Chua"],"categories":[],"content":"","date":1579275928,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579275928,"objectID":"b9df0089196231b9165749e5efeeb3aa","permalink":"https://teacherpeterpan.github.io/publication/aaai-2020/","publishdate":"2020-01-17T23:45:28+08:00","relpermalink":"/publication/aaai-2020/","section":"publication","summary":"Recognizing ingredients for a given dish image is at the core of automatic dietary assessment, attracting increasing attention from both industry and academia. Nevertheless, the task is challenging due to the difficulty of collecting and labeling sufficient training data. On one hand, there are hundred thousands of food ingredients in the world, ranging from the common to rare. Collecting training samples for all of the ingredient categories is difficult. On the other hand, as the ingredient appearances exhibit huge visual variance during the food preparation, it requires to collect the training samples under different cooking and cutting methods for robust recognition. Since obtaining sufficient fully annotated training data is not easy, a more practical way of scaling up the recognition is to develop models that are capable of recognizing unseen ingredients. Therefore, in this paper, we target the problem of ingredient recognition with zero training samples. More specifically, we introduce multi-relational GCN (graph convolutional network) that integrates ingredient hirerarchy, attribute as well as co-occurrence for zero-shot ingredient recognition. Extensive experiments on both Chinese and Japanese food datasets are performed to demonstrate the superior performance of multi-relational GCN and shed light on zero-shot ingredients recognition.","tags":[],"title":"Zero-shot Ingredient Recognition by Multi-Relational Graph Convolutional Network","type":"publication"},{"authors":null,"categories":null,"content":"","date":1569542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569542400,"objectID":"adb0b4493abbb66665061a12c910d5dc","permalink":"https://teacherpeterpan.github.io/project/question-generation/","publishdate":"2019-09-27T00:00:00Z","relpermalink":"/project/question-generation/","section":"project","summary":"A paper list that summarizes the recent papers on neural question generation.","tags":["Question Generation"],"title":"Question Generation Paper List","type":"project"},{"authors":["Liangming Pan","Wenqiang Lei","Tat-Seng Chua","Min-Yan Kan"],"categories":[],"content":"","date":1558490102,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558490102,"objectID":"324bd0be88c04577bede7112b65338ef","permalink":"https://teacherpeterpan.github.io/publication/qg-survey/","publishdate":"2019-05-22T09:55:02+08:00","relpermalink":"/publication/qg-survey/","section":"publication","summary":"Emerging research in Neural Question Generation (NQG) has started to integrate a larger variety of inputs, and generating questions requiring higher levels of cognition. These trends point to NQG as a bellwether for NLP, about how human intelligence embodies the skills of curiosity and integration. We present a comprehensive survey of neural question generation, examining the corpora, methodologies, and evaluation methods. From this, we elaborate on what we see as emerging on NQG's trend: in terms of the learning paradigms, input modalities, and cognitive levels considered by NQG. We end by pointing out the potential directions ahead.","tags":[],"title":"Recent Advances in Neural Question Generation","type":"publication"},{"authors":["Yahui An","Liangming Pan","Min-Yen Kan","Qiang Dong","Yan Fu"],"categories":[],"content":"","date":1551318970,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551318970,"objectID":"eb2011c51d47589190fae2e8a9e4b51d","permalink":"https://teacherpeterpan.github.io/publication/ieee-access/","publishdate":"2019-02-28T09:56:10+08:00","relpermalink":"/publication/ieee-access/","section":"publication","summary":"In discussions hosted on discussion forums for massive online open courses (MOOCs), references to online learning resources are often of central importance. They contextualize the discussion, anchoring the discussion participants' presentation of the issues and their understanding. However, they are usually mentioned in free text, without appropriate hyperlinking to their associated resource. Automated learning resource mention hyperlinking and categorization will facilitate discussion and searching within the MOOC forums and also benefit the contextualization of such resources across disparate views. We propose the novel problem of learning resource mention identification in MOOC forums, i.e., to identify resource mentions in discussions and classify them into pre-defined resource types. As this is a novel task with no publicly available data, we first contribute a large-scale labeled dataset-dubbed the forum resource mention (FoRM) dataset-to facilitate our current research and future research on this task. The FoRM contains over 10 000 real-world forum threads in collaboration with Coursera, with more than 23 000 manually labeled resource mentions. We then formulate this task as a sequence tagging problem and investigate solution architectures to address the problem. Importantly, we identify two major challenges that hinder the applications of sequence tagging models to the task: (1) the diversity of resource mention expression and (2) long-range contextual dependencies. We address these challenges by incorporating character-level and thread context information into an LSTM-CRF model. First, we incorporate a character encoder to address the out-of-vocabulary problem caused by the diversity of mention expressions. Second, to address the context dependency challenge, we encode thread contexts using an RNN-based context encoder and apply the attention mechanism to selectively leverage useful context information during sequence tagging. The experiments on FoRM show that the proposed method improves the baseline deep sequence tagging models notably, significantly bettering performance on instances that exemplify two challenges.","tags":[],"title":"Resource Mention Extraction for MOOC Discussion Forums","type":"publication"},{"authors":["Jifan Yu","Liangming Pan","Juanzi Li","Xiaoping Du"],"categories":[],"content":"","date":1533088584,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533088584,"objectID":"36ea01f4c1e1150ccd81a173616b38c9","permalink":"https://teacherpeterpan.github.io/publication/ccks18/","publishdate":"2018-08-01T09:56:24+08:00","relpermalink":"/publication/ccks18/","section":"publication","summary":"Applying data mining techniques to help researchers discover, understand, and predict research trends is a highly beneficial but challenging task. The existing researches mainly use topics extracted from literatures as objects to build predicting model. To get more accurate results, we use concepts instead of topics constructing a model to predict their rise and fall trends, considering the rhetorical characteristics of them. The experimental results based on ACL1965-2017 literature dataset show the clues of the scientific trends can be found in the rhetorical distribution of concepts. After adding the relevant concepts’ information, the predict model’s accuracy rate can be significantly improved, compared to the prior topic-based algorithm. ","tags":[],"title":"Predicting Concept-based Research Trends with Rhetorical Framing","type":"publication"},{"authors":["Liangming Pan","Xiaochen Wang","Chengjiang Li","Juanzi Li","Jie Tang"],"categories":[],"content":"","date":1512093378,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512093378,"objectID":"d1df4bd15b37da05986c0159c7c5bd72","permalink":"https://teacherpeterpan.github.io/publication/ijcnlp17/","publishdate":"2017-12-01T09:56:18+08:00","relpermalink":"/publication/ijcnlp17/","section":"publication","summary":"Massive Open Online Courses (MOOCs), offering a new way to study online, are revolutionizing education. One challenging issue in MOOCs is how to design effective and fine-grained course concepts such that students with different backgrounds can grasp the essence of the course. In this paper, we conduct a systematic investigation of the problem of course concept extraction for MOOCs. We propose to learn latent representations for candidate concepts via an embedding-based method. Moreover, we develop a graph-based propagation algorithm to rank the candidate concepts based on the learned representations. We evaluate the proposed method using different courses from XuetangX and Coursera. Experimental results show that our method significantly outperforms all the alternative methods (+0.013-0.318 in terms of R-precision; p","tags":[],"title":"Course Concept Extraction in MOOCs via Embedding-Based Graph Propagation","type":"publication"},{"authors":["Liangming Pan","Chengjiang Li","Juanzi Li","Jie Tang"],"categories":[],"content":"","date":1498874161,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498874161,"objectID":"9b2e3f61477636120fe243b19e0d3faa","permalink":"https://teacherpeterpan.github.io/publication/acl17/","publishdate":"2017-07-01T09:56:01+08:00","relpermalink":"/publication/acl17/","section":"publication","summary":"What prerequisite knowledge should students achieve a level of mastery before moving forward to learn subsequent coursewares? We study the extent to which the prerequisite relation between knowledge concepts in Massive Open Online Courses (MOOCs) can be inferred automatically. In particular, what kinds of information can be leverage to uncover the potential prerequisite relation between knowledge concepts. We first propose a representation learning-based method for learning latent representations of course concepts, and then investigate how different features capture the prerequisite relations between concepts. Our experiments on three datasets form Coursera show that the proposed method achieves significant improvements (+5.9-48.0% by F1-score) comparing with existing methods. ","tags":[],"title":"Prerequisite Relation Learning for Concepts in MOOCs","type":"publication"},{"authors":["Liangming Pan","Zhigang Wang","Juanzi Li","Jie Tang"],"categories":[],"content":"","date":1475286994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475286994,"objectID":"362cc5853095be919b76bd84006362ac","permalink":"https://teacherpeterpan.github.io/publication/ksem16/","publishdate":"2016-10-01T09:56:34+08:00","relpermalink":"/publication/ksem16/","section":"publication","summary":"The global knowledge sharing makes large-scale multi-lingual knowledge bases an extremely valuable resource in the Big Data era. However, current mainstream multi-lingual ontologies based on online wikis still face the limited coverage of cross-lingual knowledge links. Linking the knowledge entries distributed in different online wikis will immensely enrich the information in the online knowledge bases and benefit many applications. In this paper, we propose an unsupervised framework for cross-lingual knowledge linking. Different from traditional methods, we target the cross-lingual knowledge linking task on specific domains. We evaluate the proposed method on two knowledge linking tasks to find English-Chinese knowledge links. Experiments on English Wikipedia and Baidu Baike show that the precision improvement of cross-lingual link prediction achieve the highest 6.12 % compared with the state-of-art methods. ","tags":[],"title":"Domain Specific Cross-Lingual Knowledge Linking Based on Similarity Flooding","type":"publication"},{"authors":["Zhigang Wang","Liangming Pan","Juanzi Li","Shuangjie Li","Mingyang Li","Jie Tang"],"categories":[],"content":"","date":1473990987,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473990987,"objectID":"e670423192cf8d097a0084cde3d666b2","permalink":"https://teacherpeterpan.github.io/publication/ccks16/","publishdate":"2016-09-16T09:56:27+08:00","relpermalink":"/publication/ccks16/","section":"publication","summary":"The global knowledge sharing makes large-scale multi-lingual knowledge bases an extremely valuable resource in the Big Data era. However, current mainstream Wikipedia-based multi-lingual ontologies still face the following problems: the scarcity of non-English knowledge, the noise in the multi-lingual ontology schema relations and the limited coverage of cross-lingual owl:sameAs relations. Building a cross-lingual ontology based on other large-scale heterogenous online wikis is a promising solution for those problems. In this paper, we propose a cross-lingually boosting approach to iteratively reinforce the performance of ontology building and instance matching. Experiments output an ontology containing over 3,520,000 English instances, 800,000 Chinese instances, and over 150,000 cross-lingual instance alignments. The F1-measure improvement of Chinese instanceOf prediction achieve the highest 32%. ","tags":[],"title":"Boosting to Build a Large-Scale Cross-Lingual Ontology","type":"publication"},{"authors":["Yan Zhang","Hailong Jin","Liangming Pan","Juanzi Li"],"categories":[],"content":"","date":1472695004,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472695004,"objectID":"d88de22ba48158ca28980dc190a9577b","permalink":"https://teacherpeterpan.github.io/publication/oaei16/","publishdate":"2016-09-01T09:56:44+08:00","relpermalink":"/publication/oaei16/","section":"publication","summary":"This paper presents the results of RiMOM in the Ontology Alignment Evaluation Initiative (OAEI) 2016. RiMOM participated in all three tracks of Instance Matching this year. In this paper, we first describe the overall framework of our system (RiMOM). Then we detail the techniques used in the framework for instance matching. Last, we give a thorough analysis on our results and discuss some future work on RiMOM. ","tags":[],"title":"RiMOM results for OAEI 2016","type":"publication"}]